services:
  postgres:
    image: debezium/postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-mydb}
      PGDATA: /var/lib/postgresql/data/pgdata
    command: >
      postgres
        -c wal_level=logical
        -c max_replication_slots=4
        -c max_wal_senders=4
        -c max_worker_processes=4
    ports:
      - "${POSTGRES_PORT:-5432}:${POSTGRES_PORT:-5432}"
    volumes:
      # 1) Init-script wykona się tylko przy pierwszym starcie (pusty wolumen pgdata)
      - ./database/initdb:/docker-entrypoint-initdb.d:ro,z
      # 2) Nazwany wolumen na dane Postgresa
      - pgdata:/var/lib/postgresql/data
    restart: unless-stopped

  web:
    container_name: flask-app
    build:
      context: .
      dockerfile: Dockerfile.flask
    env_file:
      - .env
    environment:
      PYTHONPATH: /app
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_HOST: ${DB_HOST:-postgres}
      DB_PORT: ${DB_PORT:-5432}
      DB_NAME: ${DB_NAME:-mydb}
      FLASK_PORT: ${FLASK_PORT:-5000}
      FLASK_ENV: ${FLASK_ENV:-production}
      FLASK_HOST: ${FLASK_HOST:-0.0.0.0}
    ports:
      - "${FLASK_PORT:-5000}:${FLASK_PORT:-5000}"
    depends_on:
      - postgres
    
  spark:
    image: bitnami/spark:3.4.1
    container_name: spark
    depends_on:
      - kafka
      - schema-registry
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
    volumes:
      - ./spark_app:/opt/spark-app
    entrypoint: [ "/opt/bitnami/scripts/spark/entrypoint.sh", "/opt/bitnami/scripts/spark/run.sh" ]


  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT:-2181}
    ports:
      - "${ZOOKEEPER_PORT:-2181}:${ZOOKEEPER_PORT:-2181}"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:${ZOOKEEPER_PORT:-2181}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_PORT:-9092}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "${KAFKA_PORT:-9092}:${KAFKA_PORT:-9092}"

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:${KAFKA_PORT:-9092}
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
    ports:
      - "${SCHEMA_REGISTRY_PORT:-8081}:${SCHEMA_REGISTRY_PORT:-8081}"

  connect:
    build:
      context: .
      dockerfile: Dockerfile.connect
    container_name: connect
    depends_on:
      - kafka
      - schema-registry
      - postgres
    ports:
      - "${CONNECTOR_PORT:-8083}:${CONNECTOR_PORT:-8083}"
    environment:
      BOOTSTRAP_SERVERS: "kafka:${KAFKA_PORT:-9092}"
      GROUP_ID: "1"
      CONFIG_STORAGE_TOPIC: "my_connect_configs"
      OFFSET_STORAGE_TOPIC: "my_connect_offsets"
      STATUS_STORAGE_TOPIC: "my_connect_statuses"
      KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:${SCHEMA_REGISTRY_PORT:-8081}"
      # CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:${SCHEMA_REGISTRY_PORT:-8081}"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: "/kafka/connect,/usr/share/java,/etc/kafka-connect/jars"
    volumes:
      # Tu muszą trafić JAR-y Debezium i Avro Convertera
      - ./etc/kafka/connect/jars:/etc/kafka-connect/jars
    restart: unless-stopped

  connector-registrator:
    build:
      context: .
      dockerfile: Dockerfile.connector-registrator
    container_name: connector-registrator
    depends_on:
      - connect
    environment:
      CONNECTOR_PORT: ${CONNECTOR_PORT:-8083}
      DB_HOST: ${DB_HOST:-postgres}
      DB_PORT: ${DB_PORT:-5432}
      DB_USER: ${DB_USER:-postgres}
      DB_NAME: ${DB_NAME:-mydb}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_SERVER_NAME: ${DB_SERVER_NAME:-mydb_server}
      DB_TABLE: ${DB_TABLE:-public.orders,public.users}
      DB_SLOT_NAME: ${DB_SLOT_NAME:-debezium_slot}
      DB_TOPIC_PREFIX: ${DB_TOPIC_PREFIX:-dbserver1}
      SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL:-http://schema-registry:8081}

  kafka-tools:
    # image: confluentinc/cp-schema-registry:7.5.0
    build:
      context: .
      dockerfile: Dockerfile.kafka-tools
    container_name: kafka-tools
    depends_on:
      - kafka
      - schema-registry
    entrypoint: ["sh","-c","tail -f /dev/null"]

  generator:
    build: .
    container_name: generator
    depends_on:
      - postgres
    environment:
      DB_HOST: ${DB_HOST:-postgres}
      DB_PORT: ${DB_PORT:-5432}
      DB_NAME: ${DB_NAME:-mydb}
      DB_USER: ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
    command: ["python", "main.py"]

# Definicja nazwanego wolumenu (tylko ten jeden!)
volumes:
  pgdata:
